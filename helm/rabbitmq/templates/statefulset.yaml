apiVersion: apps/v1
kind: StatefulSet
metadata:
  namespace: {{ .Values.rabbitmq.namespace }}
  name: {{ include "rabbitmq.fullname" . }}
  {{- if .Values.rabbitmq.deploymenttAnnotations }}
  annotations:
    {{- with .Values.rabbitmq.deploymenttAnnotations }}
      {{- range $key, $value := . }}
      {{- printf "%s: %s" $key (tpl $value $ | quote) | nindent 4 }}
      {{- end }}
      {{- end }}
  {{- end }}
  labels:
    {{- include "rabbitmq.commonLabels" . | nindent 4 }}
    service: {{ include "rabbitmq.fullname" . }}
spec:
  replicas: {{ .Values.rabbitmq.replicas }}
  revisionHistoryLimit: 3
  selector:
    matchLabels:
      {{- include "rabbitmq.selectorLabels" . | nindent 6 }}
  # headless service that gives network identity to the RMQ nodes, and enables them to cluster
  serviceName: {{ include "rabbitmq.fullname" . }}-headless # serviceName is the name of the service that governs this StatefulSet. This service must exist before the StatefulSet, and is responsible for the network identity of the set. Pods get DNS/hostnames that follow the pattern: pod-specific-string.serviceName.default.svc.cluster.local where "pod-specific-string" is managed by the StatefulSet controller.
  volumeClaimTemplates:
    - metadata:
        name: {{ include "rabbitmq.fullname" . }}
      spec:
        storageClassName: {{ .Values.rabbitmq.pv.storage.className }}
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: {{ .Values.rabbitmq.pv.storage.capacity }}
  template:
    metadata:
      labels:
        name: {{ include "rabbitmq.fullname" . }}
        service: {{ include "rabbitmq.fullname" . }}
        {{- include "rabbitmq.selectorLabels" . | nindent 8 }}
        {{- with .Values.rabbitmq.podLabels }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
      annotations:
        {{- with .Values.rabbitmq.podAnnotations }}
          {{- range $key, $value := . }}
          {{- printf "%s: %s" $key (tpl $value $ | quote) | nindent 8 }}
          {{- end }}
          {{- end }}
    spec:
      restartPolicy: {{ .Values.rabbitmq.restartPolicy }}
      securityContext:
        {{- toYaml .Values.rabbitmq.securityContext | nindent 8 }}
      dnsPolicy: ClusterFirst
      schedulerName: default-scheduler
      terminationGracePeriodSeconds: 30
      initContainers:
        # Since k8s 1.9.4, config maps mount read-only volumes. Since the Docker image also writes to the config file,
        # the file must be mounted as read-write. We use init containers to copy from the config map read-only
        # path, to a read-write path
        - name: "rabbitmq-config"
          image: busybox:1.32.0
          volumeMounts:
            - name: certificates
              mountPath: /certificates
            - name: ca
              mountPath: /ca
            - name: certs
              mountPath: /certs
            - name: {{ include "rabbitmq.fullname" . }}-config
              mountPath: /tmp/rabbitmq
            - name: rabbitmq-config-rw
              mountPath: /etc/rabbitmq
          command:
            - sh
            - -c
            # the newline is needed since the Docker image entrypoint scripts appends to the config file
            - cp /tmp/rabbitmq/rabbitmq.conf /etc/rabbitmq/rabbitmq.conf && echo '' >> /etc/rabbitmq/rabbitmq.conf;
              cp /tmp/rabbitmq/enabled_plugins /etc/rabbitmq/enabled_plugins;
              chown -R 999:999 /etc/rabbitmq;
              cp /certs/tls.crt /certificates/tls.pem;
              printf "\n" >> /certificates/tls.pem;
              echo -en "$(cat /ca/ca-bundle.pem)" >> /certificates/tls.pem;
              echo -en "$(cat /certs/tls.key)" >> /certificates/tls.key;
              cp /ca/ca-bundle.pem /certificates/ca.crt;
              chown 999 /certificates/*;
              chmod 0400 /certificates/*;
      volumes:
        - name: certificates
          emptyDir: {}
        - name: certs
          secret:
            secretName: {{ include "rabbitmq.fullname" . }}-pod-cert
        - name: ca
          secret:
            secretName: ca
        - name: {{ include "rabbitmq.fullname" . }}-config
          configMap:
            name: {{ include "rabbitmq.fullname" . }}-config
            optional: false
            items:
              - key: enabled_plugins
                path: "enabled_plugins"
              - key: rabbitmq.conf
                path: "rabbitmq.conf"
        # read-write volume into which to copy the rabbitmq.conf and enabled_plugins files
        # this is needed since the docker image writes to the rabbitmq.conf file
        # and Kubernetes Config Maps are mounted as read-only since Kubernetes 1.9.4
        - name: rabbitmq-config-rw
          emptyDir: {}
        - name: {{ include "rabbitmq.fullname" . }}
          persistentVolumeClaim:
            claimName: {{ include "rabbitmq.fullname" . }}
      serviceAccount: rabbitmq
      # The Docker image runs as the `rabbitmq` user with uid 999
      # and writes to the `rabbitmq.conf` file
      # The security context is needed since the image needs
      # permission to write to this file. Without the security
      # context, `rabbitmq.conf` is owned by root and inaccessible
      # by the `rabbitmq` user
      containers:
        - name: {{ .Chart.Name }}
          image: "{{ .Values.rabbitmq.image.repository }}:{{ .Values.rabbitmq.image.tag }}"
          imagePullPolicy: {{ .Values.rabbitmq.image.pullPolicy }}
          securityContext:
            {{- toYaml .Values.rabbitmq.containerSecurityContext | nindent 12 }}
          {{- with .Values.rabbitmq.lifecycleHooks }}
          lifecycle:
            {{- tpl . $ | nindent 12 }}
          {{- end }}
          volumeMounts:
            # mounting rabbitmq.conf and enabled_plugins
            # this should have writeable access, this might be a problem
            - name: rabbitmq-config-rw
              mountPath: "/etc/rabbitmq"
              # mountPath: "/etc/rabbitmq/conf.d/"
            # rabbitmq data directory
            - name: {{ include "rabbitmq.fullname" . }}
              mountPath: "/var/lib/rabbitmq/mnesia"
            - name: certificates
              mountPath: /certificates
          env:
            - name: RABBITMQ_DEFAULT_PASS
              valueFrom:
                secretKeyRef:
                  name: rabbitmq-admin
                  key: pass
            - name: RABBITMQ_DEFAULT_USER
              valueFrom:
                secretKeyRef:
                  name: rabbitmq-admin
                  key: user
            - name: RABBITMQ_ERLANG_COOKIE
              valueFrom:
                secretKeyRef:
                  name: erlang-cookie
                  key: cookie
            - name: RABBITMQ_USE_LONGNAME
              value: "true"
          ports:
            - name: amqp
              containerPort: 5672
              protocol: TCP
            - name: amqps
              containerPort: 5671
              protocol: TCP
            - name: management
              containerPort: 15672
              protocol: TCP
            - name: managements
              containerPort: 15671
              protocol: TCP
            - name: epmd
              containerPort: 4369
              protocol: TCP
            - name: prometheuss
              containerPort: 15691
              protocol: TCP
            - name: prometheus
              containerPort: 15692
              protocol: TCP
            - name: cluster-rpc
              containerPort: 25672
              protocol: TCP
            - name: cluster-rpcs
              containerPort: 25671
              protocol: TCP
            - name: mqtt
              containerPort: 1883
              protocol: TCP
            - name: mqtts
              containerPort: 8883
              protocol: TCP
#          livenessProbe:
#            exec:
#              # This is just an example. There is no "one true health check" but rather
#              # several rabbitmq-diagnostics commands that can be combined to form increasingly comprehensive
#              # and intrusive health checks.
#              # Learn more at https://www.rabbitmq.com/monitoring.html#health-checks.
#              #
#              # Stage 2 check:
#              command:
#                - /bin/sh
#                - -c
#                - rabbitmq-diagnostics -q check_port_connectivity
#            initialDelaySeconds: 180
#            # See https://www.rabbitmq.com/monitoring.html for monitoring frequency recommendations.
#            periodSeconds: 60
#            timeoutSeconds: 15
#          readinessProbe: # probe to know when RMQ is ready to accept traffic
#            exec:
#              # This is just an example. There is no "one true health check" but rather
#              # several rabbitmq-diagnostics commands that can be combined to form increasingly comprehensive
#              # and intrusive health checks.
#              # Learn more at https://www.rabbitmq.com/monitoring.html#health-checks.
#              #
#              # Stage 1 check:
#              command:
#                - /bin/sh
#                - -c
#                - rabbitmq-diagnostics -q check_virtual_hosts
#            initialDelaySeconds: 120
#            periodSeconds: 60
#            timeoutSeconds: 10
          resources:
            {{- toYaml .Values.rabbitmq.resources | nindent 12 }}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
